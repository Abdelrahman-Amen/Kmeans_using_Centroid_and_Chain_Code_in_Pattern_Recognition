{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bDjLovfwz9N"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZGCf4hwxJs8p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from keras.datasets import mnist\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import adjusted_rand_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV338rcSw5zQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Qy4-_1nFzL",
        "outputId": "a8a88ad9-c589-4852-8a4c-58a0754bd15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Concatenate train_images with test_images\n",
        "images = np.concatenate((train_images, test_images), axis=0)\n",
        "# images=images/255\n",
        "# Concatenate train_labels with test_labels\n",
        "labels = np.concatenate((train_labels, test_labels), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PVQHHJ3Kt8pa"
      },
      "outputs": [],
      "source": [
        "# Create train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m5-RrCnvmSB",
        "outputId": "df8cdf10-d0d6-49b5-b24c-29f57669b91e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              " array([6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "unique_values, counts = np.unique(labels,return_counts=True)\n",
        "unique_values,counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1lF2GgOxRVE"
      },
      "source": [
        "#Centroid Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zw9-vVWXnGGf"
      },
      "outputs": [],
      "source": [
        "def extract_features(image, rows, cols):\n",
        "    features = []\n",
        "    grid_height = image.shape[0] // rows\n",
        "    grid_width = image.shape[1] // cols\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            # Calculate coordinates for the current grid cell\n",
        "            x1 = i * grid_height\n",
        "            x2 = x1 + grid_height\n",
        "            y1 = j * grid_width\n",
        "            y2 = y1 + grid_width\n",
        "\n",
        "            # Extract the sub-image (grid cell) from the original image\n",
        "            grid_cell = image[x1:x2, y1:y2]\n",
        "\n",
        "            # Calculate the centroid coordinates for the grid cell\n",
        "            sum_f = np.sum(grid_cell)\n",
        "            rowss, columns = grid_cell.shape\n",
        "            x_bar = np.sum(np.array([[x] * rowss for x in range(rowss)]) * grid_cell) / sum_f if sum_f != 0 else 0\n",
        "            y_bar = np.sum(np.array([[y] * columns for y in range(columns)]) * grid_cell) / sum_f if sum_f != 0 else 0\n",
        "\n",
        "            # Store the centroid coordinates as features for this grid cell\n",
        "            features.append(x_bar)\n",
        "            features.append(y_bar)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBOuvPDPw_o8"
      },
      "source": [
        "#Extract chain code from contour using 8-connectivity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "coVYCV7wnGMd"
      },
      "outputs": [],
      "source": [
        "def extract_chain_code(contour):\n",
        "    chain_code = []\n",
        "    directions = [(0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1)]  # 8 Connectivity\n",
        "\n",
        "    for i in range(len(contour) - 1):\n",
        "        dx = contour[i+1][0][0] - contour[i][0][0]\n",
        "        dy = contour[i+1][0][1] - contour[i][0][1]\n",
        "\n",
        "        # Normalize dx and dy to be in range [-1, 1]\n",
        "        dx_normalized = np.sign(dx)\n",
        "        dy_normalized = np.sign(dy)\n",
        "\n",
        "        direction = directions.index((dx_normalized, dy_normalized))\n",
        "        chain_code.append(direction)\n",
        "\n",
        "    return chain_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RkR2pn9xClV"
      },
      "source": [
        "#Calculate chain code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QVrmo63KnGJk"
      },
      "outputs": [],
      "source": [
        "def calculate_chain_code_dimensions(image):\n",
        "    # Threshold the image\n",
        "    _, thresholded_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Find the largest contour\n",
        "    largest_contour = max(contours, key=cv2.contourArea)  # Processing the most significant part of the image\n",
        "\n",
        "    # Get chain code sequence for the largest contour\n",
        "    chain_code_sequence = extract_chain_code(largest_contour)\n",
        "\n",
        "    return chain_code_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i-YF-nUeqES6"
      },
      "outputs": [],
      "source": [
        "# Calculate chain code dimensions for all images\n",
        "chain_code_sequences = []\n",
        "for image in X_train:\n",
        "    sequence = calculate_chain_code_dimensions(image)\n",
        "    chain_code_sequences.append(sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bmShPN3LqEVs"
      },
      "outputs": [],
      "source": [
        "# Pad chain codes with zeros to make them uniform\n",
        "max_length = max(len(code) for code in chain_code_sequences)\n",
        "chain_codes_padded = [code + [8] * (max_length - len(code)) for code in chain_code_sequences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EStnHlRyxE6t"
      },
      "source": [
        "# kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QiEFcELsaxRd"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "def assign_labels(X, centroids):\n",
        "    labels = []\n",
        "    for point in X:\n",
        "        distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
        "        label = np.argmin(distances)\n",
        "        labels.append(label)\n",
        "    return np.array(labels)\n",
        "\n",
        "def update_centroids(X, labels, k):\n",
        "    centroids = np.zeros((k, X.shape[1]))\n",
        "    for i in range(k):\n",
        "        cluster_points = X[labels == i]\n",
        "        if len(cluster_points) > 0:\n",
        "            centroids[i] = np.mean(cluster_points, axis=0)\n",
        "    return centroids\n",
        "\n",
        "def kmeans(X, k, max_iters=100):\n",
        "    centroids = X[np.random.choice(range(X.shape[0]), size=k, replace=False)]\n",
        "    for _ in range(max_iters):\n",
        "        labels = assign_labels(X, centroids)\n",
        "        new_centroids = update_centroids(X, labels, k)\n",
        "        if np.all(centroids == new_centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "    return centroids, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NDaq74eJnlp3"
      },
      "outputs": [],
      "source": [
        "def count_samples_in_clusters(labels, k):\n",
        "    counts = np.zeros(k, dtype=int)\n",
        "    for label in labels:\n",
        "        counts[label] += 1\n",
        "    return counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_Y88qDRxXS4"
      },
      "source": [
        "# Extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7t5BpOW1nnNP"
      },
      "outputs": [],
      "source": [
        "rows = 3\n",
        "cols = 3\n",
        "# Step 4: Extract features from images using centroid and chain code\n",
        "centroid_features = np.array([extract_features(image, rows, cols) for image in X_train])\n",
        "# chain_code_features = np.array([calculate_chain_code_dimensions(image) for image in images])\n",
        "chain_code_features = np.array(chain_codes_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikxd6bWApNy_",
        "outputId": "74c3ef2a-bdad-4eca-8e89-b82cccb9c4a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56000, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "centroid_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72PcTEq6r2OM",
        "outputId": "92e8fa4c-47d3-4574-ae6a-551096d2823c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56000, 73)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "chain_code_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hA4oxuinnqKf"
      },
      "outputs": [],
      "source": [
        "k = 10    #initialize number of clusters   Note:it's 10 clusters as we have 10 classses\n",
        "centroids_centroid, labels_centroid = kmeans(centroid_features, k)\n",
        "centroids_chain, labels_chain = kmeans(chain_code_features, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OSjqIIYMnwsI"
      },
      "outputs": [],
      "source": [
        "counts_centroid = count_samples_in_clusters(labels_centroid, k)\n",
        "counts_chain = count_samples_in_clusters(labels_chain, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2GVTd2VsCSn",
        "outputId": "db4d7c27-ed76-44c9-b90f-f01502913486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 18), (56000,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "centroids_centroid.shape,labels_centroid.shape   # 10*18    70000*1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxtQv7X6sYhO",
        "outputId": "21d2f510-24d0-4ae0-e7b5-a3ecf0c3d5ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 73), (56000,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "centroids_chain.shape,labels_chain.shape     # 10*73      70000*1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbzC8HZdxI6M"
      },
      "source": [
        "# Compare with actual distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpeawuManyJX",
        "outputId": "a545dcce-6f00-43c9-f17e-9f6c7ca770c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual counts per class: [5560 6277 5610 5708 5529 5040 5480 5790 5468 5538]\n",
            "Counts using centroid features: [3746 9129 6619 2769 5418 5256 4087 7503 7588 3885]\n",
            "Counts using chain code features: [5404 4458 5032 7327 4415 5354 6216 6057 4059 7678]\n"
          ]
        }
      ],
      "source": [
        "# Compare with actual distribution\n",
        "actual_counts = np.bincount(y_train)\n",
        "print(\"Actual counts per class:\", actual_counts)\n",
        "print(\"Counts using centroid features:\", counts_centroid)\n",
        "print(\"Counts using chain code features:\", counts_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snd7nK6Yszii",
        "outputId": "325b25bd-7bf2-4fb3-a56e-accfcacf0263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56000, 56000, 56000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "np.sum(actual_counts),np.sum(counts_chain),np.sum(counts_centroid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rxNN0gv0BJ9"
      },
      "source": [
        "Adjusted Rand Index (ARI)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNZbiNVpxymu",
        "outputId": "f2994aef-8c90-473b-e34c-656256dd7396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARI for centroid features: 0.1432602275345006\n",
            "ARI for chain code features: 0.11069838606403704\n"
          ]
        }
      ],
      "source": [
        "#The Adjusted Rand Index (ARI)\n",
        "\n",
        "# Calculate ARI for centroid features\n",
        "ari_centroid = adjusted_rand_score(y_train, labels_centroid)\n",
        "\n",
        "# Calculate ARI for chain code features\n",
        "ari_chain = adjusted_rand_score(y_train, labels_chain)\n",
        "\n",
        "print(\"ARI for centroid features:\", ari_centroid)\n",
        "print(\"ARI for chain code features:\", ari_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZQ3mMMhrlR",
        "outputId": "c5b8a319-ae85-45bd-89ac-506184813ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using centroid features: 0.3575357142857143\n",
            "Accuracy using chain code features: 0.319875\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "def map_cluster_labels(labels, true_labels):\n",
        "    mapped_labels = np.zeros_like(labels)\n",
        "    for i in range(k):\n",
        "        mask = (labels == i)\n",
        "        mapped_labels[mask] = mode(true_labels[mask])[0]\n",
        "    return mapped_labels\n",
        "\n",
        "def calculate_accuracy(predicted_labels, true_labels):\n",
        "    correct = np.sum(predicted_labels == true_labels)\n",
        "    total = len(true_labels)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Map cluster labels to true labels\n",
        "mapped_labels_centroid = map_cluster_labels(labels_centroid, y_train)\n",
        "mapped_labels_chain = map_cluster_labels(labels_chain, y_train)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_centroid = calculate_accuracy(mapped_labels_centroid, y_train)\n",
        "accuracy_chain = calculate_accuracy(mapped_labels_chain, y_train)\n",
        "\n",
        "print(\"Accuracy using centroid features:\", accuracy_centroid)\n",
        "print(\"Accuracy using chain code features:\", accuracy_chain)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}